# -*- coding: utf-8 -*-
"""(Updated) ML Terapan_Proyek Kedua - Sistem Rekomendasi

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oylqKitkoxC4hGF0NTrn8TEWoH0UHtdv

# Sistem Rekomendasi Film – Tiesya Andriani Ramadhanti MC189D5X0428

Proyek ini bertujuan untuk membangun sistem rekomendasi film yang dapat memberikan rekomendasi film sesuai dengan preferensi pengguna berdasarkan berbagai fitur film seperti genre, rating, tahun rilis, durasi, dan ulasan pengguna. Dengan memanfaatkan dataset film yang kaya akan informasi, model ini diharapkan dapat membantu penonton menemukan film yang paling relevan dan menarik bagi mereka.

## 📊 Sumber Dataset  
Dataset yang digunakan berasal dari Kaggle:  
🔗 [Movie Recommendation System – Kaggle](https://www.kaggle.com/datasets/parasharmanas/movie-recommendation-system)

Dataset ini mencakup berbagai informasi terkait film, termasuk judul, genre, rating dari pengguna, serta metadata lainnya yang sangat berguna dalam membangun model rekomendasi berbasis machine learning dan algoritma filtering.

# **Import Library**
"""

!pip install -q kaggle

# Manipulasi data
import pandas as pd
import numpy as np

# Visualisasi (opsional)
import matplotlib.pyplot as plt
import seaborn as sns

# Preprocessing teks
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Untuk collaborative filtering
from scipy.sparse import csr_matrix
from sklearn.neighbors import NearestNeighbors

# Warnings
import warnings
warnings.filterwarnings('ignore')

from collections import Counter

"""# **Data Understanding**

## Load Dataset
"""

from google.colab import files
uploaded = files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d rohan4050/movie-recommendation-data

!unzip movie-recommendation-data.zip -d movie_data

movies_df = pd.read_csv('/content/movie_data/ml-latest-small/movies.csv')
ratings_df = pd.read_csv('/content/movie_data/ml-latest-small/ratings.csv')
tags_df = pd.read_csv('/content/movie_data/ml-latest-small/tags.csv')
links_df = pd.read_csv('/content/movie_data/ml-latest-small/links.csv')

"""## Menampilkan informasi dataset

### movies.csv
"""

print("Movies Data Head:")
# Menampilkan beberapa baris pertama sebagai cek
movies_df.head()

movies_df.info()

movies_df.describe()

"""### Insight Awal Dataset `movies`

#### 🧾 Struktur Data
- Dataset terdiri dari **9742 entri film** dengan 3 kolom:
- `movieId` (int64): ID unik untuk setiap film.
- `title` (object): Judul film (mengandung tahun rilis dalam format `(YYYY)`).
- `genres` (object): Satu atau lebih genre, dipisahkan dengan simbol `|`.
- Semua kolom memiliki **9742 nilai non-null** — artinya data tidak memiliki nilai kosong.

#### 📈 Statistik Kolom `movieId`
- ID film dimulai dari **1** hingga **193609**, menunjukkan bahwa ID tidak urut dan memiliki banyak loncatan.
- **Nilai tengah (median)** `movieId` adalah **7300**, sedangkan nilai rata-rata mencapai **42200**, yang menunjukkan sebaran data yang miring ke kanan (right-skewed).
- **25%** film memiliki `movieId` ≤ 3248, dan **75%** film memiliki `movieId` ≤ 76232.
- Standar deviasi yang tinggi (**52160.49**) mengonfirmasi penyebaran nilai ID yang sangat lebar.

### ratings.csv
"""

print("Ratings Data Head:")
# Menampilkan beberapa baris pertama sebagai cek
ratings_df.head()

ratings_df.info()

ratings_df.describe()

"""### Insight Awal Dataset Ratings

#### 🧾 Struktur Data
- Dataset memiliki **100,836 entri** dan terdiri dari **4 kolom**:
`userId` (int64): ID pengguna yang memberikan rating.
- `movieId` (int64): ID film yang diberi rating.
- `rating` (float64): Nilai rating antara 0.5 sampai 5.0.
- `timestamp` (int64): Waktu rating dalam format Unix timestamp.

Semua kolom memiliki nilai lengkap (**tidak ada missing values**).


#### 📈 Statistik Kolom Numerik
- **userId**:
  - Terdapat 610 pengguna unik (min=1, max=610).
  - Distribusi cukup merata (mean ~326, median 325).

- **movieId**:
  - Film yang dirating memiliki ID antara 1 hingga 193609.
  - Rata-rata `movieId` adalah 19.435, namun distribusi skewed (median=2.991).
  - Ini menunjukkan sebagian besar rating diberikan untuk film-film dengan ID lebih kecil (kemungkinan film lebih populer atau lebih lama).

- **rating**:
  - Skala penilaian: 0.5 (min) hingga 5.0 (max).
  - Rata-rata rating adalah **3.50**, dengan nilai tengah juga **3.5**.
  - Rating cenderung condong ke nilai positif, menunjukkan pengguna cenderung memberikan penilaian baik.

- **timestamp**:
  - Representasi waktu dalam Unix timestamp (detik sejak 1 Januari 1970).
  - Perlu dikonversi ke format datetime untuk analisis tren waktu.
  - Median timestamp: sekitar **1.18 miliar detik** atau kira-kira sekitar **tahun 2000-an akhir hingga 2010-an awal**.

### tags.csv
"""

print("Tags Data Head:")
# Menampilkan beberapa baris pertama sebagai cek
tags_df.head()

tags_df.info()

tags_df.describe()

"""### Insight Awal Dataset Tags

#### 🧾 Struktur Data
- Dataset memiliki **3683 entri** dengan 4 kolom:
  - `userId` (int64): ID pengguna yang memberikan tag.
  - `movieId` (int64): ID film yang ditandai.
  - `tag` (object): Teks tag yang diberikan oleh pengguna.
  - `timestamp` (int64): Waktu pemberian tag dalam format Unix timestamp.
- Semua kolom memiliki **nilai lengkap (non-null)** — tidak ada data yang hilang.

#### 📈 Statistik Kolom Numerik
- **userId**:
  - Jumlah pengguna: ID berkisar dari 2 hingga 610.
  - Median `userId`: 474, menunjukkan keterlibatan aktif dari pengguna tengah.

- **movieId**:
  - ID film berkisar dari 1 hingga 193565, menunjukkan bahwa tag diberikan pada berbagai rentang film.
  - Median film ID adalah 4454, dengan nilai maksimum tinggi — menunjukkan sebagian kecil film dengan ID besar juga menerima tag.

- **timestamp**:
  - Timestamp berkisar dari **1.13 miliar** hingga **1.53 miliar** detik sejak Unix epoch.
  - Median waktu menunjukkan aktivitas tagging sekitar **tahun 2010-an**, dengan sebagian besar aktivitas terjadi dalam rentang waktu modern.
  - Perlu dikonversi ke format datetime untuk analisis tren waktu tagging.

### links.csv
"""

print("Links Data Head:")
# Menampilkan beberapa baris pertama sebagai cek
links_df.head()

links_df.info()

links_df.describe()

"""### Insight Awal Dataset Links

#### 🧾 Struktur Data
- Dataset memiliki **9742 entri** dengan 3 kolom:
  - `movieId`: ID film yang digunakan dalam dataset utama.
  - `imdbId`: ID film pada basis data **IMDb**.
  - `tmdbId`: ID film pada basis data **TMDb (The Movie Database)**.

#### 🔍 Kualitas Data
- Semua baris memiliki `movieId` dan `imdbId`.
- Namun, kolom `tmdbId` memiliki **8 nilai yang hilang**, sehingga perlu penanganan jika digunakan untuk integrasi eksternal.

#### 📊 Statistik Kolom
- **movieId**:
  - Sama seperti dataset `movies`, menunjukkan bahwa dataset `links` adalah pelengkap langsung untuk `movies.csv`.

- **imdbId & tmdbId**:
  - Masing-masing memiliki rentang ID yang sangat luas, menunjukkan variasi film dari era yang berbeda dan berbagai genre.
  - Nilai **`tmdbId`** minimum hanya `2`, sementara maksimum lebih dari `525 ribu`, menunjukkan cakupan sangat luas dari film modern hingga yang sangat lama atau jarang.

# **Univariate Exploratory Data Analysis**

## Dataset Movie Recommendation

Dataset ini terdiri dari empat file utama, yaitu `movies.csv`, `ratings.csv`, `tags.csv`, dan `links.csv`. Masing-masing file berisi informasi yang saling terhubung berdasarkan `movieId`.

### 🎬 movies.csv
Berisi informasi dasar mengenai film yang tersedia dalam sistem.

**Variabel:**
- `movieId` : ID unik dari setiap film.
- `title` : Judul film beserta tahun rilis.
- `genres` : Genre dari film tersebut (dipisahkan dengan tanda | jika lebih dari satu).

### ⭐ ratings.csv
Berisi data penilaian (rating) yang diberikan oleh pengguna terhadap film.

**Variabel:**
- `userId` : ID unik pengguna yang memberi rating.
- `movieId` : ID film yang diberi rating.
- `rating` : Nilai rating yang diberikan (biasanya skala 0.5 - 5.0).
- `timestamp` : Waktu pemberian rating dalam format UNIX timestamp.

### 🏷️ tags.csv
Berisi tag atau kata kunci yang diberikan pengguna terhadap film.

**Variabel:**
- `userId` : ID unik pengguna.
- `movieId` : ID film yang diberi tag.
- `tag` : Kata kunci atau deskripsi yang diberikan pengguna.
- `timestamp` : Waktu saat tag diberikan (format UNIX timestamp).

### 🔗 links.csv
Berisi tautan referensi eksternal ke database film seperti IMDb dan TMDb.

**Variabel:**
- `movieId` : ID unik film.
- `imdbId` : ID film di database IMDb.
- `tmdbId` : ID film di database TMDb.

### Univariate EDA Movies
"""

# Hitung jumlah film unik berdasarkan movieId
jumlah_film_unik = movies_df['movieId'].nunique()
print(f"Jumlah film unik: {jumlah_film_unik}")

"""- Dataset `movies` memiliki **9.742 film unik** berdasarkan `movieId`.
- Hal ini menunjukkan bahwa setiap film diidentifikasi secara unik, tanpa duplikasi ID.

"""

# Hitung jumlah kemunculan masing-masing movieId di data ratings

movie_id_title = movies_df.drop_duplicates(subset=['movieId'])[['movieId', 'title']].set_index('movieId')
movie_id_counts = ratings_df['movieId'].value_counts()
movie_summary = movie_id_title.join(movie_id_counts.rename('Jumlah_Rating'))
movie_summary = movie_summary.sort_index()
movie_summary = movie_summary[['title', 'Jumlah_Rating']]
movie_summary = movie_summary.reset_index()

movie_summary

"""- Terdapat 9.742 film dengan jumlah rating yang bervariasi.
- Beberapa film populer seperti Toy Story (1995) mendapatkan jumlah rating tinggi (215 kali), menunjukkan tingkat popularitas dan eksposur yang tinggi.
- Sebagian besar film hanya mendapatkan 1 rating, yang menunjukkan bahwa dataset memiliki banyak film dengan eksposur rendah atau niche.
- Distribusi rating ini bersifat right-skewed yaitu hanya sedikit film yang sering dirating, sementara sebagian besar film jarang dirating.
"""

# Menghitung frekuensi semua genre
genre_counts = Counter()
for genres in movies_df['genres']:
    genre_counts.update(genres.split('|'))

# Ubah menjadi DataFrame
genre_df = pd.DataFrame(genre_counts.items(), columns=['Genre', 'Jumlah'])
genre_df = genre_df.sort_values(by='Jumlah', ascending=False)


# Cetak jumlah genre
print(f"Jumlah genre film: {len(genre_counts)}")


# Visualisasi semua genre
plt.figure(figsize=(12, 8))
sns.barplot(data=genre_df, y='Genre', x='Jumlah', palette='viridis')
plt.title("Jumlah Film per Genre (Semua Genre)")
plt.xlabel("Jumlah Film")
plt.ylabel("Genre")
plt.tight_layout()
plt.show()

"""Berdasarkan grafik jumlah film per genre, dapat disimpulkan bahwa genre Drama dan Comedy merupakan yang paling banyak diproduksi, diikuti oleh Thriller, Action, dan Romance, yang juga menunjukkan popularitas tinggi di industri film. Sementara itu, genre seperti IMAX, Film-Noir, dan (no genres listed) memiliki jumlah film paling sedikit. Data ini mencerminkan keragaman genre dalam industri film serta dapat dijadikan acuan untuk melihat tren pasar, menyusun strategi produksi, atau mengeksplorasi genre-genre yang masih jarang digarap.

### Univariate EDA ratings
"""

# Jumlah pengguna unik
jumlah_user = ratings_df['userId'].nunique()
print(f"Jumlah user unik: {jumlah_user}")

# Distribusi jumlah rating per user
user_rating_counts = ratings_df['userId'].value_counts()

# Visualisasi top 20 user paling aktif
plt.figure(figsize=(12, 6))  # Perbesar ukuran figure
sns.barplot(x=user_rating_counts.head(20).index.astype(str),
            y=user_rating_counts.head(20).values,
            palette='viridis')

plt.title("Top 20 User dengan Jumlah Rating Terbanyak")
plt.xlabel("User ID")
plt.ylabel("Jumlah Rating")
plt.xticks(rotation=45, ha='right')  # Putar label sumbu-x agar mudah dibaca
plt.tight_layout()
plt.show()

"""Berdasarkan grafik di atas, terlihat bahwa pengguna dengan ID 414 merupakan user yang memberikan rating terbanyak, disusul oleh user ID 599, 474, dan 448. Jumlah rating yang diberikan oleh pengguna menurun secara bertahap dari kiri ke kanan, menunjukkan distribusi kontribusi rating yang tidak merata di mana hanya sebagian kecil pengguna yang sangat aktif dalam memberikan penilaian. Hal ini dapat dimanfaatkan untuk memahami perilaku pengguna aktif serta menentukan target dalam strategi personalisasi atau promosi yang lebih tepat sasaran."""

# Jumlah film unik yang dirating
jumlah_film_dirating = ratings_df['movieId'].nunique()
print(f"Jumlah film yang diberi rating: {jumlah_film_dirating}")

# Distribusi jumlah rating per film
movie_rating_counts = ratings_df['movieId'].value_counts()

# Visualisasi top 20 film paling banyak diberi rating
plt.figure(figsize=(10, 5))
sns.barplot(x=movie_rating_counts.head(20).index.astype(str), y=movie_rating_counts.head(20).values, palette='viridis')
plt.title("Top 20 Film dengan Jumlah Rating Terbanyak")
plt.xlabel("Movie ID")
plt.ylabel("Jumlah Rating")
plt.tight_layout()
plt.show()

# Statistik deskriptif rating
print(ratings_df['rating'].describe())

# Visualisasi distribusi rating
plt.figure(figsize=(8, 5))
sns.histplot(ratings_df['rating'], bins=10, kde=True, color='skyblue', edgecolor='black')
plt.title("Distribusi Nilai Rating Film oleh User")
plt.xlabel("Rating")
plt.ylabel("Jumlah")
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""#### Insight dari ratings

### Univariate EDA Links
"""

# Cek duplikat dan nilai kosong
print("Jumlah movieId unik:", links_df['movieId'].nunique())
print("Jumlah data duplikat:", links_df.duplicated().sum())
print("Missing values:\n", links_df.isnull().sum())

"""- Terdapat **9.742 movieId unik**, yang konsisten dengan jumlah film unik di dataset utama.
- **Tidak ada data duplikat** pada dataset `links_df`, menunjukkan data sudah bersih dari pengulangan baris.
- Ada **8 missing values** pada kolom `tmdbId`, sementara kolom `movieId` dan `imdbId` tidak memiliki nilai kosong.

### Univariate EDA Tags
"""

# Ambil 10 tag teratas
top_tags = tags_df['tag'].value_counts().head(10)

# Ubah ke DataFrame untuk mempermudah plotting dengan seaborn
top_tags_df = top_tags.reset_index()
top_tags_df.columns = ['tag', 'frekuensi']

# Visualisasi menggunakan seaborn
plt.figure(figsize=(10, 5))
sns.barplot(data=top_tags_df, y='tag', x='frekuensi', palette='viridis')
plt.title("10 Tag Terpopuler dari Pengguna")
plt.xlabel("Frekuensi")
plt.ylabel("Tag")
plt.tight_layout()
plt.show()

# Cek duplikat dan nilai kosong
print("Jumlah movieId unik:", tags_df['movieId'].nunique())
print("Jumlah data duplikat:", tags_df.duplicated().sum())
print("Missing values:\n", tags_df.isnull().sum())

"""#### Insight dari Tags

# **Data Preprocessing**

## Menggabungkan Variabel `movieId` Seluruh Dataset
"""

# Menggabungkan seluruh movieID dari 4 dataset (movies, ratings, tags, links)
all_movies = np.concatenate((
    movies_df.movieId.unique(),
    ratings_df.movieId.unique(),
    tags_df.movieId.unique(),
    links_df.movieId.unique(),
))

# Menghapus duplikat sekaligus mengurutkan movieId unik
all_movies = np.sort(np.unique(all_movies))

# Menampilkan jumlah movieId unik
print('Jumlah seluruh data movie berdasarkan movieID: ', len(all_movies))

"""- Setelah menggabungkan dan menghilangkan duplikat dari keempat dataset (`movies`, `ratings`, `tags`, dan `links`), didapatkan **9.742 movieId unik**.
- Ini menunjukkan bahwa **semua dataset konsisten dan terintegrasi dengan baik** dalam hal referensi film yang sama.
- Jumlah ini sama dengan jumlah film unik pada dataset `movies`, mengindikasikan tidak ada film baru yang hanya muncul di dataset lain tanpa tercatat di `movies`.

## Menggabungkan Seluruh User
"""

# Menggabungkan seluruh userId
all_users = np.concatenate((
    ratings_df.userId.unique(),
    tags_df.userId.unique(),

))

# Menghapus data yang sama kemudian mengurutkannya
all_users = np.sort(np.unique(all_users))

print('Jumlah seluruh user: ', len(all_users))

"""- Total terdapat **610 user unik** yang berinteraksi dalam dataset, baik melalui pemberian **rating** maupun penambahan **tag**.
- Karena jumlah ini merupakan hasil penggabungan dari dua sumber (`ratings_df` dan `tags_df`), maka **tidak ada user tambahan** yang hanya ada di salah satu dataset saja, artinya semua user yang memberi tag juga setidaknya memberi rating.
- Ini menunjukkan bahwa aktivitas pengguna di sistem lebih terkonsentrasi pada pemberian rating dibandingkan penambahan tag, dan tidak ada user yang eksklusif hanya menambahkan tag tanpa pernah memberi rating.

## Menggabungkan Seluruh Dataset
"""

# Merge datasets step-by-step
movie_merge = ratings_df.merge(movies_df, on='movieId', how='left') \
                        .merge(links_df, on='movieId', how='left') \
                        .merge(tags_df[['userId', 'movieId', 'tag']], on=['userId', 'movieId'], how='left')

# Hapus baris duplikat jika ada (berdasarkan userId dan movieId)
movie_merge = movie_merge.drop_duplicates(subset=['userId', 'movieId'])

# Urutkan berdasarkan userId dan movieId agar rapi
movie_merge = movie_merge.sort_values(by=['userId', 'movieId']).reset_index(drop=True)

# Tampilkan hasil
movie_merge

"""- Total data setelah penggabungan dan pembersihan: **100.836 baris**.
- Masing-masing baris merepresentasikan **satu rating unik** dari seorang user terhadap satu film.
- Kolom `tag` memiliki banyak nilai **NaN**, mengindikasikan bahwa:
  - Sebagian besar pengguna **tidak memberikan tag** pada film yang mereka rating.
  - Aktivitas pemberian tag dilakukan oleh sebagian kecil pengguna saja.

## Memeriksa Missing Value
"""

movie_merge.isnull().sum()

"""Berdasarkan hasil pengecekan *missing values* pada dataframe `movie_merge`, diperoleh hasil sebagai berikut:

- Tidak ada nilai yang hilang pada kolom-kolom utama seperti `userId`, `movieId`, `rating`, `timestamp`, `title`, `genres`, dan `imdbId`, yang berarti data tersebut lengkap untuk keperluan analisis rating dan metadata film.
- Terdapat **13 missing values pada kolom `tmdbId`**, yang artinya ada 13 film yang tidak memiliki ID referensi ke database TMDB.
- Kolom `tag` memiliki **99.201 missing values**, menandakan bahwa sebagian besar film tidak diberikan tag oleh pengguna. Hal ini wajar karena tagging bersifat opsional dan dilakukan oleh sebagian kecil pengguna saja.

## Penggabungan Rating Berdasarkan Variabel `movieId`
"""

movie_merge.groupby('movieId').sum()

"""Berdasarkan hasil agregasi dataset `ratings_df` yang digabungkan berdasarkan `movieId`, diperoleh dataframe berukuran **9.724 baris**, masing-masing mewakili satu `movieId`. Setiap baris mewakili data film yang telah digabungkan dengan informasi tambahan dari berbagai tabel (`movies`, `links`, dan `tags`), serta dilakukan agregasi yaitu sum terhadap rating dan jumlah user yang memberikan rating.

## Menyimpan Data Rating Film
"""

all_movie_rate = ratings_df
all_movie_rate

"""##Menggabungkan Data Rating dengan Informasi Film

"""

all_movie_name = pd.merge(all_movie_rate, movies_df[['movieId','title','genres']], on='movieId', how='left')
all_movie_name

"""## Penggabungan Data Genre dan Tag pada Film

"""

# Menggabungkan dataframe genres dengan all_movie_name dan memasukkannya ke dalam variabel all_movie
all_movie = pd.merge(all_movie_name, tags_df[['movieId','tag']], on='movieId', how='left')
all_movie

"""# **Data Preparation**

## Mengatasi Missing Value
"""

# Cek missing value pada variabel `all_movie`
all_movie.isnull().sum()

"""- **Tidak ada missing value pada kolom penting:**  
  Kolom `userId`, `movieId`, `rating`, `timestamp`, `title`, dan `genres` tidak memiliki nilai kosong sama sekali. Ini menunjukkan data utama untuk analisis rating dan film sudah lengkap dan siap digunakan.

- **Kolom `tag` memiliki missing value cukup banyak:**  
  Terdapat 52.549 missing value pada kolom `tag`. Ini cukup signifikan dan menunjukkan bahwa banyak film atau rating tidak memiliki tag yang terkait. Bisa jadi pengguna tidak selalu memberikan tag saat memberi rating, atau data tag tidak lengkap.
  
Maka dilakukan pembersihan missing value dengan fungsi dropna() untuk menghilangkan missing value tersebut.
"""

clean_all_movie = all_movie.dropna()
clean_all_movie

# Cek kembali missing valuenya
clean_all_movie.isnull().sum()

"""Setelah dilakukan pembersihan missing value menggunakan fungsi dropna()
tidak ditemukan lagi missing value dalam kolom `tag`

## Tahapan Pengurutan dan Pemeriksaan Film Unik
"""

final_movie= clean_all_movie.sort_values('movieId', ascending=True)
final_movie

"""- **Data Terurut Berdasarkan `movieId` Dari Kecil Ke Besar(ascending)**
  Pengurutan ini memudahkan untuk melihat data film secara sistematis berdasarkan ID film, dari film dengan `movieId` terkecil hingga terbesar. Ini membantu dalam menelusuri atau memeriksa data film secara berurutan tanpa loncatan antar film.
"""

# Cek jumlah film unik berdasarkan kolom movieId dalam variabel final_movie
len(final_movie.movieId.unique())

"""## Menyalin Isi `final_movie` Dalam Variabel `prepared_movies`

"""

prepared_movies = final_movie.sort_values('movieId').reset_index(drop=True)
prepared_movies

"""## Hapus Data Duplikat"""

# Mengecek jumlah duplikat berdasarkan movieId
jumlah_duplikat = prepared_movies.duplicated('movieId').sum()
print(f"Jumlah duplikat berdasarkan movieId: {jumlah_duplikat}")

# Menghapus duplikat berdasarkan movieId
prepared_movies = prepared_movies.drop_duplicates('movieId')

# Menampilkan data setelah duplikat dihapus
prepared_movies

"""## Konversi Data Series Menjadi List"""

# Mengonversi data series ‘movieId’ menjadi dalam bentuk list
movie_id = prepared_movies['movieId'].tolist()

# Mengonversi data series ‘title’ menjadi dalam bentuk list
movie_name = prepared_movies['title'].tolist()

# Mengonversi data series ‘genres’ menjadi dalam bentuk list
movie_genre = prepared_movies['genres'].tolist()

print(len(movie_id))
print(len(movie_name))
print(len(movie_genre))

"""## Membuat DataFrame Baru"""

# Membuat dictionary untuk data ‘movie_id’, ‘movie_name’, dan ‘movie_genre’
new_movies = pd.DataFrame({
    'id': movie_id,
    'movie_name': movie_name,
    'genre': movie_genre
})
new_movies

"""- Dilakukan pembuatan dictionary Python yang berisi tiga key utama (id, movie_name, dan genre) yang masing-masing diisi oleh list/array dari variabel movie_id, movie_name, dan movie_genre.
- Dengan menyusun data dalam bentuk dictionary lalu mengubahnya menjadi DataFrame, kita bisa dengan mudah mengakses informasi film berdasarkan id, melihat distribusi genre, dan mengolah judul.

## Persiapan Content Based Filtering

### Menggunakan fungsi TFIDFVectorizer()
"""

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data genre
tf.fit(new_movies['genre'])

# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

"""### Ekstraksi Fitur Kedalam Bentuk Matriks

Pada proses ini, dilakukan transformasi teks dari kolom `genre` menggunakan teknik **TF-IDF (Term Frequency - Inverse Document Frequency)** dengan bantuan `TfidfVectorizer` dari pustaka `sklearn`.
"""

tfidf_matrix = tf.fit_transform(new_movies['genre'])
tfidf_matrix.shape

"""### Konversi Sparse ke Dense Matrix"""

tfidf_matrix.todense()

# Melihat matriks tf-idf untuk beberapa movie (movie_name) dan genre
pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=new_movies.movie_name
).sample(22, axis=1).sample(10, axis=0)

"""### Menggunakan Cosine Similarity

Cosine Similarity digunakan untuk menghitung derajat kesamaan (similarity degree) antar movie dengan teknik cosine similarity.
"""

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""### Membuat Dataframe `cosine_sim_df`


"""

cosine_sim_df = pd.DataFrame(cosine_sim, index=new_movies['movie_name'], columns=new_movies['movie_name'])
print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""### Membuat fungsi movie_recommendations

Fungsi movie_recommendationsdibuat dengan beberapa parameter sebagai berikut:

- **Nama_film** merupakan nama judul dari movie tersebut (index kemiripan dataframe).
- **Similarity_data** merpakan datataframe mengenai similarity yang telah kita didefinisikan sebelumnya
- **Items** merupakan nama dan fitur yang digunakan untuk mendefinisikan kemiripan, dalam hal ini adalah ‘movie_name’ dan ‘genre’.
- **x** merupakan banyak rekomendasi yang ingin diberikan.


"""

def movie_recommendations(nama_film, similarity_data=cosine_sim_df, items=new_movies[['movie_name', 'genre']], k=10):
    index = similarity_data.loc[:, nama_film].to_numpy().argpartition(range(-1, -k, -1))
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    closest = closest.drop(nama_film, errors='ignore')
    return pd.DataFrame(closest).merge(items).head(k)

"""## Persiapan Collaborative Filtering

### Membuat salinan variabel ratings_df dengan dataframe baru
"""

df = ratings_df
df

"""### Melakukan Proses Encoding"""

# Mengubah userID menjadi list tanpa nilai yang sama
user_ids = df['userId'].unique().tolist()
print('list userID: ', user_ids)

# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userID: ', user_encoded_to_user)

"""### Proses Encoding Untuk `movieId`"""

# Mengubah movieId menjadi list tanpa nilai yang sama
movie_ids = df['movieId'].unique().tolist()

# Melakukan proses encoding movieId
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}

# Melakukan proses encoding angka ke movieId
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}

# Selanjutnya, petakan userId dan movieId ke dataframe yang berkaitan.

# Mapping userId ke dataframe genres
df['genres'] = df['userId'].map(user_to_user_encoded)

# Mapping movieD ke dataframe movies
df['movies'] = df['movieId'].map(movie_to_movie_encoded)

"""#### Insight dari Proses Encoding userId

1. **Pengambilan userId unik**  
   Dengan menggunakan `df_ratings_new['userId'].unique()`, didapatkan daftar userId tanpa duplikasi, sehingga setiap user hanya dihitung sekali. Ini penting untuk memastikan mapping user ke angka tidak dobel.

2. **Encoding userId ke angka bertipe indeks**  
   Encoding userId ke angka (`user_to_user_encoded`) memudahkan proses komputasi dalam machine learning, khususnya dalam model rekomendasi yang biasanya memerlukan input dalam bentuk indeks numerik mulai dari 0.  
   Contoh: userId asli 1 di-mapping menjadi 0, userId 2 menjadi 1, dan seterusnya.

### Cek Data Pada Dataframe `df`
"""

num_users = len(user_to_user_encoded)
print(num_users)

num_movie = len(movie_encoded_to_movie)
print(num_movie)

df['ratings'] = df['rating'].values.astype(np.float32)

min_rating = min(df['rating'])

max_rating = max(df['rating'])

print('Number of User: {}, Number of movie: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, min_rating, max_rating
))

# Dilakukan pengacakan data
df = df.sample(frac=1, random_state=42)
df

"""### Split Dataset

Membagi dataset menjadi 80% untuk pelatihan dan 20% untuk validasi.
"""

# Menggabungkan kolom genres dan movies menjadi array fitur x
x = df.loc[:, ['genres', 'movies']].to_numpy()

# Menormalisasi kolom ratings ke rentang 0 hingga 1 sebagai target y
y = (df['ratings'] - min_rating) / (max_rating - min_rating)
y = y.to_numpy()

# Menentukan indeks batas untuk split data 80% train dan 20% validasi
split_point = int(len(df) * 0.8)

# Membagi data menjadi data latih dan validasi berdasarkan indeks split
x_train = x[:split_point]
x_val = x[split_point:]
y_train = y[:split_point]
y_val = y[split_point:]

print(x, y)

"""# **Modeling & Results**

## 1. Model Sistem Rekomendasi dengan Content Based Filltering

## Hasil Rekomendasi Top-N dari Content-Based Filtering
"""

new_movies[new_movies.movie_name.eq('Poltergeist II: The Other Side (1986)')]

"""Berdasarkan hasil yang didapat, kode ini berhasil memfilter dan menampilkan data film 'Poltergeist II: The Other Side (1986)' beserta atribut terkait seperti id dan genre. Hal ini menunjukkan bahwa pencarian film berdasarkan judul di dataset new_movies berhasil dilakukan.

Fungsi rekomendasi yang dibuat sebelumnya, digunakan untuk menemukan rekomendasi film yang mirip dengan Poltergeist II: The Other Side (1986)
"""

movie_recommendations('Poltergeist II: The Other Side (1986)')

"""Berdasarkan hasil yang didapat, fungsi movie_recommendations berhasil memberikan rekomendasi film yang memiliki genre serupa dengan film 'Poltergeist II: The Other Side (1986)', yaitu genre Horror dan Thriller. Rekomendasi ini relevan karena semua film yang muncul memiliki tema seram dan menegangkan yang sama, sehingga sangat cocok bagi penonton yang menyukai film tersebut. Ini menunjukkan bahwa metode berbasis kemiripan genre dengan cosine similarity mampu menghasilkan daftar film rekomendasi yang konsisten dan sesuai preferensi.

## 2. Model Sistem Rekomendasi dengan Collaborative Content Filltering

## Melakukan Proses Training
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path

class RecommenderNet(tf.keras.Model):

    def __init__(self, num_users, num_movies, embedding_dim, **kwargs):
        super().__init__(**kwargs)
        self.num_users = num_users
        self.num_movies = num_movies
        self.embedding_dim = embedding_dim

        self.user_embedding = layers.Embedding(
            input_dim=num_users,
            output_dim=embedding_dim,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )
        self.user_bias = layers.Embedding(input_dim=num_users, output_dim=1)

        self.movie_embedding = layers.Embedding(
            input_dim=num_movies,
            output_dim=embedding_dim,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )
        self.movie_bias = layers.Embedding(input_dim=num_movies, output_dim=1)

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0])
        user_bias = self.user_bias(inputs[:, 0])
        movie_vector = self.movie_embedding(inputs[:, 1])
        movie_bias = self.movie_bias(inputs[:, 1])

        dot_product = tf.tensordot(user_vector, movie_vector, axes=2)

        output = dot_product + user_bias + movie_bias

        return tf.nn.sigmoid(output)

# Inisialisasi model dengan embedding size 50
model = RecommenderNet(num_users=num_users, num_movies=num_movie, embedding_dim=50)

# Kompilasi model
model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError(),tf.keras.metrics.MeanAbsoluteError()]
)

# Melakukan proses pelatihan model
history = model.fit(
    x_train,
    y_train,
    batch_size=64,
    epochs=100,
    validation_data=(x_val, y_val)
)

"""## Hasil Rekomendasi Top-N dari Collaborative Filtering

"""

df_movie = new_movies
df = pd.read_csv('movie_data/ml-latest-small/ratings.csv')

# Ambil satu user secara acak
user_id = df['userId'].sample(1).iloc[0]
movie_watched_by_user = df[df['userId'] == user_id]

# Cari movie yang belum ditonton user
movie_not_watched = df_movie[~df_movie['id'].isin(movie_watched_by_user['movieId'])]['id']

# Filter movie yang ada di encoding
movie_not_watched = list(
    set(movie_not_watched).intersection(set(movie_to_movie_encoded.keys()))
)

# Ubah movie_not_watched menjadi list of lists dengan encoded id
movie_not_watched = [[movie_to_movie_encoded[movie_id]] for movie_id in movie_not_watched]

# Ambil encoded user id
user_encoder = user_to_user_encoded[user_id]

# Buat array input untuk user dan movie yang belum ditonton
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_not_watched), movie_not_watched)
)

"""### Menggunakan Fungsi model.predict()

Fungsi ini digunakan untuk memperoleh rekomendasi movies dari library Keras
"""

df = model.predict(user_movie_array).flatten()

top_ratings_indices = df.argsort()[-10:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movie_not_watched[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('movie with high ratings from user')
print('----' * 8)

top_movie_user = (
    movie_watched_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)

movie_df_rows = df_movie[df_movie['id'].isin(top_movie_user)]
for row in movie_df_rows.itertuples():
    print(row.movie_name, ':', row.genre)

print('----' * 8)
print('Top 10 movie recommendation')
print('----' * 8)

recommended_movie = df_movie[df_movie['id'].isin(recommended_movie_ids)]
for row in recommended_movie.itertuples():
    print(row.movie_name, ':', row.genre)

"""### Insight Rekomendasi Film untuk User 480

Berdasarkan histori penilaian user 480, terlihat bahwa film-film dengan rating tertinggi didominasi oleh genre **Comedy**, **Drama**, dan beberapa genre aksi seperti **Action** dan **Sci-Fi**. Contohnya adalah film seperti *Office Space (1999)* dan *Matrix, The (1999)* yang menunjukkan preferensi terhadap film populer dan beragam genre.

Rekomendasi film yang diberikan memperlihatkan variasi genre yang cukup luas, dengan dominasi pada **Drama**, **Romance**, serta beberapa genre seperti **Comedy**, **War**, dan **Animation**. Hal ini mengindikasikan bahwa sistem rekomendasi berusaha mengeksplorasi kemungkinan ketertarikan user terhadap genre yang lebih emosional dan beragam, mungkin berdasarkan pola kesamaan preferensi antar pengguna lain.

Menariknya, beberapa film klasik seperti *Paths of Glory (1957)* dan *Jetée, La (1962)* menunjukkan bahwa sistem tidak hanya merekomendasikan film modern, tetapi juga menawarkan tontonan bernilai sejarah dan sinematik tinggi. Pendekatan ini dapat memperkenalkan user pada variasi film yang lebih luas dan mendalam.

Secara keseluruhan, rekomendasi ini memperlihatkan pendekatan diversifikasi genre yang seimbang, dengan harapan dapat memperluas preferensi tontonan user 480 tanpa keluar dari zona kenyamanannya.

# **Evaluation**

## Evaluasi Model Sistem Rekomendasi Content Based Filtering
"""

def evaluate_precision_recall_at_k(nama_film, k=10):
    # Film yang direkomendasikan
    recommended_df = movie_recommendations(nama_film, k=k)

    # Genre dari film input
    input_genre = new_movies[new_movies['movie_name'] == nama_film]['genre'].values[0]

    # Anggap film dengan genre yang sama = relevan
    recommended_genres = recommended_df['genre'].values
    relevan_count = sum([1 for genre in recommended_genres if genre == input_genre])

    # Total film relevan dalam keseluruhan dataset (tidak termasuk film input)
    total_relevan = new_movies[(new_movies['genre'] == input_genre) & (new_movies['movie_name'] != nama_film)].shape[0]

    # Hitung Precision@K dan Recall@K
    precision_at_k = relevan_count / k
    recall_at_k = relevan_count / total_relevan if total_relevan != 0 else 0

    return {
        'Precision@{}'.format(k): round(precision_at_k, 4),
        'Recall@{}'.format(k): round(recall_at_k, 4),
        'Relevant Recommended': relevan_count,
        'Total Relevant in Dataset': total_relevan
    }

# Contoh penggunaan:
evaluate_precision_recall_at_k("Poltergeist II: The Other Side (1986)", k=10)

"""### Interpretasi Hasil

- **Precision@10 = 0.8**  
  Dari 10 film yang direkomendasikan, sebanyak 8 film tergolong relevan (memiliki genre yang sama atau serupa dengan film input). Ini menunjukkan bahwa sistem cukup selektif dalam memberikan rekomendasi yang sesuai.

- **Recall@10 = 0.8889**  
  Dari total 9 film yang relevan di seluruh dataset, sistem berhasil merekomendasikan 8 di antaranya. Ini menandakan bahwa sistem memiliki cakupan yang sangat baik dalam menemukan film-film relevan.

Secara keseluruhan, nilai precision dan recall yang tinggi ini menunjukkan bahwa sistem rekomendasi content-based yang dibangun memiliki **kinerja yang baik dalam memberikan saran film yang relevan bagi pengguna**.

## Evaluasi Model Sistem Rekomendasi Collaborative Filtering
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Grafik Root Mean Squared Error (RMSE) menunjukkan bahwa error pada data pelatihan menurun tajam pada awal pelatihan dan kemudian stabil mendekati nilai 0.20. Nilai RMSE training terakhir tercatat sebesar 0.2002, sedangkan RMSE pada data validasi stabil di kisaran 0.208.
Tren yang stabil dan tidak terlalu fluktuatif mengindikasikan bahwa model mampu belajar dari data tanpa mengalami overfitting yang signifikan.
"""

plt.plot(history.history['mean_absolute_error'])
plt.plot(history.history['val_mean_absolute_error'])
plt.title('Model MAE')
plt.ylabel('mean_absolute_error')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

"""Grafik Mean Absolute Error (MAE) memperlihatkan penurunan drastis pada awal pelatihan dan kemudian stabil. Nilai MAE training terakhir tercatat sebesar 0.1563, sedangkan MAE validasi stabil di kisaran 0.161.
Pola ini menunjukkan bahwa model menghasilkan prediksi yang cukup akurat dan konsisten baik pada data pelatihan maupun data validasi.
"""